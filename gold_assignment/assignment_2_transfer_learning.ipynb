{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16fecd865b4c4d8aa382c126ba03e730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1512d22e2a29484e83c8dfc166706ce9",
              "IPY_MODEL_08a07e2cc3c04621a5c22d2d2d863ab6",
              "IPY_MODEL_4b5fa46463a5418a8c1425233285d079"
            ],
            "layout": "IPY_MODEL_1c30d7bc70c04c069278a3529fdc1af7"
          }
        },
        "1512d22e2a29484e83c8dfc166706ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_185dba6a081e4e3e9332ef32a6a2e10d",
            "placeholder": "​",
            "style": "IPY_MODEL_d034fa4fbb7c4384b17943c4a09d369d",
            "value": "Map: 100%"
          }
        },
        "08a07e2cc3c04621a5c22d2d2d863ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85f6f889172e4f7fb6bd90a7487f6f6c",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8402370b6a44daaa5820e1508696f11",
            "value": 25
          }
        },
        "4b5fa46463a5418a8c1425233285d079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0bd8641f7fa4b6babae9b7218f9ffcf",
            "placeholder": "​",
            "style": "IPY_MODEL_44603800f4eb4beeaefb5f32b1d7ca60",
            "value": " 25/25 [00:00&lt;00:00, 1002.53 examples/s]"
          }
        },
        "1c30d7bc70c04c069278a3529fdc1af7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "185dba6a081e4e3e9332ef32a6a2e10d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d034fa4fbb7c4384b17943c4a09d369d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85f6f889172e4f7fb6bd90a7487f6f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8402370b6a44daaa5820e1508696f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0bd8641f7fa4b6babae9b7218f9ffcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44603800f4eb4beeaefb5f32b1d7ca60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26d88e4c28ba4e6dadd776b5da21cfbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0229adce63546da8d6ee2098720116b",
              "IPY_MODEL_152740d7b5964cb58f0dd0d5463cb133",
              "IPY_MODEL_9452bdecf08e48489d8779d438cd8568"
            ],
            "layout": "IPY_MODEL_e237b16bb25d4b0eb6b80919220513d6"
          }
        },
        "c0229adce63546da8d6ee2098720116b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d75ceb5b37334d14b1b3335588acf066",
            "placeholder": "​",
            "style": "IPY_MODEL_e64f3b19162545b0a224056c0345e20c",
            "value": "Map: 100%"
          }
        },
        "152740d7b5964cb58f0dd0d5463cb133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_233025abefc046198ae842ec210da68d",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_169520e90bde4b0da56afa905788fb22",
            "value": 7
          }
        },
        "9452bdecf08e48489d8779d438cd8568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bd10c790a9145d3b842898cd7b8d91e",
            "placeholder": "​",
            "style": "IPY_MODEL_ad6d8c37ad3d47a59dcb7ff33c8dfe12",
            "value": " 7/7 [00:00&lt;00:00, 390.28 examples/s]"
          }
        },
        "e237b16bb25d4b0eb6b80919220513d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d75ceb5b37334d14b1b3335588acf066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e64f3b19162545b0a224056c0345e20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "233025abefc046198ae842ec210da68d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "169520e90bde4b0da56afa905788fb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bd10c790a9145d3b842898cd7b8d91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad6d8c37ad3d47a59dcb7ff33c8dfe12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashNigam65/gitfolder/blob/master/genAI_concept_notebook/fine_tunning_and_transfer_learning/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement transfer learning using an LLM that is used by all like Mistral or Claude with a small dataset for a chosen task."
      ],
      "metadata": {
        "id": "-3moaCKgKgKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # Import the PyTorch library for deep learning operations\n",
        "import torch.nn as nn # Import neural network modules from PyTorch\n",
        "from transformers import (\n",
        "    AutoTokenizer, # Tool to load pre-trained tokenizers for text processing\n",
        "    AutoModel, # Tool to load pre-trained models for various tasks\n",
        "    AutoModelForSequenceClassification, # Specific model for sequence classification tasks\n",
        "    TrainingArguments, # Class to define training configurations\n",
        "    Trainer, # High-level API for training models\n",
        "    DataCollatorWithPadding # Helper to pad and batch input data\n",
        ")\n",
        "\n",
        "from datasets import Dataset # Import Dataset class from Hugging Face Datasets library for easy data handling\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support # Import metrics for evaluating model performance\n",
        "import numpy as np # Import NumPy for numerical operations, especially for array manipulation"
      ],
      "metadata": {
        "id": "CnoNH_hGwbjJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using **\"distilbert-base-uncased\"** model because it offers a great balance of speed, efficiency, and strong general performance for transfer learning in text classification, being a smaller, faster version of BERT."
      ],
      "metadata": {
        "id": "emJBEkCVzRD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**num_labels= 2**\n",
        "\n",
        "The num_labels parameter specifies the number of output classes for your classification task. In this specific code, it's set to 2 because the sample sentiment analysis problem is a binary classification task. This means there are only two possible categories or sentiments: 'positive' (represented by 1) and 'negative' (represented by 0).\n",
        "\n",
        "When AutoModelForSequenceClassification is loaded, this num_labels value tells the model how many output neurons or classes the final classification layer should have to make its predictions. For our sentiment analysis, it needs to distinguish between positive and negative, hence 2 labels."
      ],
      "metadata": {
        "id": "o8G7nW4vzNBO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JL9Qrme5XY0w"
      },
      "outputs": [],
      "source": [
        "# Sample data for sentiment analysis\n",
        "sample_data = {\n",
        "    'texts': [\n",
        "        \"I love this product, it's amazing!\",\n",
        "        \"This is terrible, worst purchase ever.\",\n",
        "        \"The weather is nice today.\",\n",
        "        \"I hate waiting in long queues.\",\n",
        "        \"This movie was fantastic and entertaining.\",\n",
        "        \"The service was disappointing and slow.\",\n",
        "        \"What a beautiful sunset tonight.\",\n",
        "        \"I'm frustrated with this situation.\",\n",
        "        \"This book is incredibly well written.\",\n",
        "        \"The food was bland and overpriced.\",\n",
        "        \"I enjoy spending time with friends.\",\n",
        "        \"This software is buggy and unreliable.\",\n",
        "        \"The concert was absolutely wonderful.\",\n",
        "        \"I'm tired of all these problems.\",\n",
        "        \"This vacation was the best ever!\",\n",
        "        \"The meeting was boring and pointless.\",\n",
        "        \"Absolutely thrilled with the results, truly impressed.\",\n",
        "        \"Couldn't be more unhappy, a complete disaster.\",\n",
        "        \"The coffee was strong and just what I needed.\",\n",
        "        \"A truly dreadful experience from start to finish.\",\n",
        "        \"Highly recommend this place, it's a gem!\",\n",
        "        \"Such a waste of time and money, totally regret it.\",\n",
        "        \"Fantastic performance, everyone should see it.\",\n",
        "        \"Utterly useless, I can't believe I bought this.\",\n",
        "        \"The customer support was exceptional and very helpful.\",\n",
        "        \"Never again! This was the worst decision.\",\n",
        "        \"Smiling from ear to ear, feeling so happy.\",\n",
        "        \"Feeling incredibly down and disappointed today.\",\n",
        "        \"The new features are brilliant and well-implemented.\",\n",
        "        \"This app constantly crashes, very annoying.\",\n",
        "        \"What a pleasant surprise, exceeded all expectations.\",\n",
        "        \"Everything went wrong, a truly awful day.\"\n",
        "    ],\n",
        "    'labels': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
        "}  # 1: positive, 0: negative\n",
        "\n",
        "class TransferLearningModel:\n",
        "    \"\"\"\n",
        "    A class to handle transfer learning for text classification\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"distilbert-base-uncased\", num_labels=2):\n",
        "        \"\"\"\n",
        "        Initialize the transfer learning model\n",
        "\n",
        "        Args:\n",
        "            model_name: Pre-trained model to use as base\n",
        "            num_labels: Number of classes for the new task\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.num_labels = num_labels\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Set device to GPU if available, else CPU\n",
        "\n",
        "\n",
        "    def load_pretrained_model(self):\n",
        "        \"\"\"\n",
        "        Load the pre-trained model and tokenizer\n",
        "        \"\"\"\n",
        "        print(f\"Loading pre-trained model: {self.model_name}\")\n",
        "\n",
        "        # Load tokenizer from the specified pre-trained model name\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "\n",
        "        # Load model for sequence classification from the specified pre-trained model name\n",
        "        # This automatically adds a classification head on top of the base model\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            self.model_name,\n",
        "            num_labels=self.num_labels\n",
        "        ).to(self.device) # Move the model to the specified device (CPU/GPU)\n",
        "\n",
        "        print(f\"Model loaded successfully!\")\n",
        "        print(f\"Model has {self.model.num_parameters()} parameters\")\n",
        "\n",
        "    def prepare_dataset(self, texts, labels, max_length=128):\n",
        "        \"\"\"\n",
        "        Prepare dataset for training/evaluation by tokenizing texts\n",
        "        and creating a Hugging Face Dataset object\n",
        "        \"\"\"\n",
        "        def tokenize_function(examples):\n",
        "            # Tokenize a batch of examples, truncating and padding to max_length\n",
        "            return self.tokenizer(\n",
        "                examples['text'],\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=max_length,\n",
        "                return_tensors=\"pt\" # Return PyTorch tensors\n",
        "            )\n",
        "\n",
        "        # Create a Hugging Face Dataset from the provided texts and labels\n",
        "        dataset = Dataset.from_dict({\n",
        "            'text': texts,\n",
        "            'labels': labels\n",
        "        })\n",
        "\n",
        "        # Apply the tokenization function to the dataset\n",
        "        tokenized_dataset = dataset.map(tokenize_function, batched=True) # Process in batches for efficiency\n",
        "\n",
        "        return tokenized_dataset\n",
        "\n",
        "    def compute_metrics(self, eval_pred):\n",
        "        \"\"\"\n",
        "        Compute metrics (accuracy, precision, recall, f1) for evaluation\n",
        "        \"\"\"\n",
        "        predictions, labels = eval_pred\n",
        "        predictions = np.argmax(predictions, axis=1) # Get the predicted class by taking the argmax of logits\n",
        "\n",
        "        # Calculate precision, recall, f1-score, and accuracy\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "        accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'precision': precision,\n",
        "            'recall': recall\n",
        "        }\n",
        "\n",
        "    def train(self, train_texts, train_labels, eval_texts=None, eval_labels=None):\n",
        "        \"\"\"\n",
        "        Train the model using transfer learning with the Hugging Face Trainer API\n",
        "        \"\"\"\n",
        "        print(\"Preparing training dataset...\")\n",
        "        train_dataset = self.prepare_dataset(train_texts, train_labels)\n",
        "\n",
        "        eval_dataset = None\n",
        "        if eval_texts and eval_labels:\n",
        "            print(\"Preparing evaluation dataset...\")\n",
        "            eval_dataset = self.prepare_dataset(eval_texts, eval_labels)\n",
        "\n",
        "        # Data collator for dynamic padding of batches during training\n",
        "        data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
        "\n",
        "        # Define training arguments\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=\"./transfer_learning_model\", # Directory to save model checkpoints and logs\n",
        "            num_train_epochs=100, # Total number of training epochs (increased for small dataset)\n",
        "            per_device_train_batch_size=8, # Batch size per device during training\n",
        "            per_device_eval_batch_size=8, # Batch size per device during evaluation\n",
        "            warmup_steps=10, # Number of warmup steps for learning rate scheduler (reduced)\n",
        "            weight_decay=0.01, # Strength of weight decay\n",
        "            logging_dir=\"./logs\", # Directory for storing logs\n",
        "            logging_steps=10, # Log every N updates steps\n",
        "            eval_strategy=\"epoch\" if eval_dataset else \"no\", # Evaluate at the end of each epoch if eval_dataset is provided\n",
        "            save_strategy=\"epoch\", # Save checkpoint at the end of each epoch\n",
        "            load_best_model_at_end=True if eval_dataset else False, # Load the best model (based on metric_for_best_model) at the end of training\n",
        "            metric_for_best_model=\"accuracy\" if eval_dataset else None, # Metric to use for early stopping/best model selection\n",
        "            report_to=None,  # Disable reporting to platforms like wandb\n",
        "        )\n",
        "\n",
        "        # Initialize the Hugging Face Trainer\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            tokenizer=self.tokenizer,\n",
        "            data_collator=data_collator,\n",
        "            compute_metrics=self.compute_metrics if eval_dataset else None, # Function to compute metrics during evaluation\n",
        "        )\n",
        "\n",
        "        # Train the model\n",
        "        print(\"Starting transfer learning training...\")\n",
        "        trainer.train()\n",
        "\n",
        "        # Save the trained model and tokenizer\n",
        "        trainer.save_model(\"./transfer_learning_model\")\n",
        "        self.tokenizer.save_pretrained(\"./transfer_learning_model\")\n",
        "\n",
        "        print(\"Transfer learning completed!\")\n",
        "\n",
        "        return trainer\n",
        "\n",
        "    def predict(self, texts):\n",
        "        \"\"\"\n",
        "        Make predictions on new texts using the trained model\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not loaded. Call load_pretrained_model() first.\")\n",
        "\n",
        "        self.model.eval() # Set the model to evaluation mode\n",
        "        predictions = []\n",
        "\n",
        "        for text in texts:\n",
        "            # Tokenize the input text\n",
        "            inputs = self.tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\", # Return PyTorch tensors\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=128\n",
        "            )\n",
        "\n",
        "            # Move inputs to the same device as the model (CPU/GPU)\n",
        "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "            # Make prediction without computing gradients\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "                logits = outputs.logits # Get the raw output scores\n",
        "                predicted_class = torch.argmax(logits, dim=1).item() # Get the class with the highest score\n",
        "                confidence = torch.softmax(logits, dim=1).max().item() # Get the confidence for the predicted class\n",
        "\n",
        "                predictions.append({\n",
        "                    'text': text,\n",
        "                    'predicted_class': predicted_class,\n",
        "                    'confidence': confidence\n",
        "                })\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def demonstrate_different_approaches():\n",
        "#     \"\"\"\n",
        "#     Demonstrate different transfer learning approaches: full fine-tuning and feature extraction.\n",
        "#     \"\"\"\n",
        "#     print(\"=== APPROACH 1: Full Fine-tuning ===\")\n",
        "#     # Initialize and load a model for full fine-tuning (all layers are trainable)\n",
        "#     model1 = TransferLearningModel(\"distilbert-base-uncased\")\n",
        "#     model1.load_pretrained_model()\n",
        "\n",
        "#     # Split the sample data into training and testing sets\n",
        "#     train_size = int(0.8 * len(sample_data['texts']))\n",
        "#     train_texts = sample_data['texts'][:train_size]\n",
        "#     train_labels = sample_data['labels'][:train_size]\n",
        "#     test_texts = sample_data['texts'][train_size:]\n",
        "#     test_labels = sample_data['labels'][train_size:]\n",
        "\n",
        "#     # Train the first model (full fine-tuning)\n",
        "#     trainer1 = model1.train(train_texts, train_labels, test_texts, test_labels)\n",
        "\n",
        "#     print(\"\\n=== APPROACH 2: Feature Extraction (Frozen Base) ===\")\n",
        "#     # Initialize and load a second model for feature extraction\n",
        "#     model2 = TransferLearningModel(\"distilbert-base-uncased\")\n",
        "#     model2.load_pretrained_model()\n",
        "\n",
        "#     # Freeze the parameters of the base DistilBERT model so only the classification head is trained\n",
        "#     for param in model2.model.distilbert.parameters():\n",
        "#         param.requires_grad = False\n",
        "\n",
        "#     print(\"Frozen base model parameters. Only training classification head.\")\n",
        "#     # Train the second model (feature extraction)\n",
        "#     trainer2 = model2.train(train_texts, train_labels, test_texts, test_labels)\n",
        "\n",
        "#     return model1, model2 # Return both trained models"
      ],
      "metadata": {
        "id": "2yW4nhnsYFg2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demonstrate_different_approaches():\n",
        "    \"\"\"\n",
        "    Demonstrate different transfer learning approaches: full fine-tuning and feature extraction.\n",
        "    \"\"\"\n",
        "    # print(\"=== APPROACH 1: Full Fine-tuning ===\")\n",
        "    # # Initialize and load a model for full fine-tuning (all layers are trainable)\n",
        "    # model1 = TransferLearningModel(\"distilbert-base-uncased\")\n",
        "    # model1.load_pretrained_model()\n",
        "\n",
        "    # Split the sample data into training and testing sets\n",
        "    train_size = int(0.8 * len(sample_data['texts']))\n",
        "    train_texts = sample_data['texts'][:train_size]\n",
        "    train_labels = sample_data['labels'][:train_size]\n",
        "    test_texts = sample_data['texts'][train_size:]\n",
        "    test_labels = sample_data['labels'][train_size:]\n",
        "\n",
        "    # # Train the first model (full fine-tuning)\n",
        "    # trainer1 = model1.train(train_texts, train_labels, test_texts, test_labels)\n",
        "\n",
        "    print(\"\\n=== APPROACH 1: Feature Extraction (Frozen Base) ===\")\n",
        "    # Initialize and load a second model for feature extraction\n",
        "    model1 = TransferLearningModel(\"distilbert-base-uncased\")\n",
        "    model1.load_pretrained_model()\n",
        "\n",
        "    # Freeze the parameters of the base DistilBERT model so only the classification head is trained\n",
        "    for param in model1.model.distilbert.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    print(\"Frozen base model parameters. Only training classification head.\")\n",
        "    # Train the second model (feature extraction)\n",
        "    trainer1 = model1.train(train_texts, train_labels, test_texts, test_labels)\n",
        "\n",
        "    return model1 # Return both trained models"
      ],
      "metadata": {
        "id": "sQnOGLVWG7a4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_test_model(model_path=\"./transfer_learning_model\"):\n",
        "    \"\"\"\n",
        "    Load a previously saved model and tokenizer, then make predictions on new examples.\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== TESTING SAVED MODEL ===\")\n",
        "\n",
        "    # Load the saved model for sequence classification and its tokenizer\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "    # Create an instance of TransferLearningModel and assign the loaded model and tokenizer\n",
        "    transfer_model = TransferLearningModel()\n",
        "    transfer_model.model = model.to(transfer_model.device) # Move the loaded model to the correct device (CPU/GPU)\n",
        "    transfer_model.tokenizer = tokenizer\n",
        "\n",
        "    # Define new examples to test the loaded model\n",
        "    test_examples = [\n",
        "        \"This is absolutely wonderful!\",\n",
        "        \"I'm really disappointed with this.\",\n",
        "        \"The weather looks great today.\",\n",
        "        \"This is the worst experience ever.\",\n",
        "        \"I love how this works perfectly.\"\n",
        "    ]\n",
        "\n",
        "    # Get predictions from the loaded model\n",
        "    predictions = transfer_model.predict(test_examples)\n",
        "\n",
        "    print(\"Predictions on new examples:\",predictions)\n",
        "    # Print each prediction with its sentiment and confidence\n",
        "    for pred in predictions:\n",
        "        sentiment = \"Positive\" if pred['predicted_class'] == 1 else \"Negative\"\n",
        "        print(f\"Text: '{pred['text']}'\")\n",
        "        print(f\"Predicted: {sentiment} (Confidence: {pred['confidence']:.3f})\")\n",
        "        print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "swvlxhOTYIN0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to orchestrate the demonstration of transfer learning, including training and prediction.\n",
        "    \"\"\"\n",
        "    print(\"Transfer Learning with Language Models\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Check and print the available device (GPU or CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    try:\n",
        "        # Demonstrate both full fine-tuning and feature extraction approaches\n",
        "        #model1, model2 = demonstrate_different_approaches()\n",
        "        model1= demonstrate_different_approaches()\n",
        "\n",
        "        # Define new texts for testing predictions with the first trained model\n",
        "        test_texts = [\n",
        "            \"This product is amazing!\",\n",
        "            \"I hate this so much.\",\n",
        "            \"Pretty decent overall.\",\n",
        "        ]\n",
        "\n",
        "        print(\"\\n=== MAKING PREDICTIONS ===\")\n",
        "        # Get predictions from the fully fine-tuned model\n",
        "        predictions = model1.predict(test_texts)\n",
        "        print(\"Predictions with full fine-tuning:\", predictions)\n",
        "        # Print the predictions with sentiment and confidence\n",
        "        for pred in predictions:\n",
        "            sentiment = \"Positive\" if pred['predicted_class'] ==1 else \"Negative\"\n",
        "            print(f\"Text: '{pred['text']}'\")\n",
        "            print(f\"Prediction: {sentiment} (Confidence: {pred['confidence']:.3f})\")\n",
        "            print(\"-\" * 30)\n",
        "\n",
        "        # Test loading a saved model and making predictions with it\n",
        "        load_and_test_model()\n",
        "\n",
        "    except Exception as e:\n",
        "        # Handle potential errors and provide instructions for installing dependencies\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        print(\"\\nMake sure you have the required packages:\")\n",
        "        print(\"pip install torch transformers datasets scikit-learn\")"
      ],
      "metadata": {
        "id": "XRwYbG7XX7qm"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers datasets scikit-learn # Install necessary libraries: PyTorch, Hugging Face Transformers, Hugging Face Datasets, and scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0CSgL4-Ybs1",
        "outputId": "b07438ce-5431-49c0-e920-37cb72affe85"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main() # Call the main function to start the demonstration when the script is executed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "16fecd865b4c4d8aa382c126ba03e730",
            "1512d22e2a29484e83c8dfc166706ce9",
            "08a07e2cc3c04621a5c22d2d2d863ab6",
            "4b5fa46463a5418a8c1425233285d079",
            "1c30d7bc70c04c069278a3529fdc1af7",
            "185dba6a081e4e3e9332ef32a6a2e10d",
            "d034fa4fbb7c4384b17943c4a09d369d",
            "85f6f889172e4f7fb6bd90a7487f6f6c",
            "f8402370b6a44daaa5820e1508696f11",
            "b0bd8641f7fa4b6babae9b7218f9ffcf",
            "44603800f4eb4beeaefb5f32b1d7ca60",
            "26d88e4c28ba4e6dadd776b5da21cfbd",
            "c0229adce63546da8d6ee2098720116b",
            "152740d7b5964cb58f0dd0d5463cb133",
            "9452bdecf08e48489d8779d438cd8568",
            "e237b16bb25d4b0eb6b80919220513d6",
            "d75ceb5b37334d14b1b3335588acf066",
            "e64f3b19162545b0a224056c0345e20c",
            "233025abefc046198ae842ec210da68d",
            "169520e90bde4b0da56afa905788fb22",
            "1bd10c790a9145d3b842898cd7b8d91e",
            "ad6d8c37ad3d47a59dcb7ff33c8dfe12"
          ]
        },
        "id": "eHTvGeRJYKV-",
        "outputId": "4537db82-2755-4da7-949d-965208af9a0b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transfer Learning with Language Models\n",
            "==================================================\n",
            "Using device: cuda\n",
            "\n",
            "=== APPROACH 1: Feature Extraction (Frozen Base) ===\n",
            "Loading pre-trained model: distilbert-base-uncased\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n",
            "Model has 66955010 parameters\n",
            "Frozen base model parameters. Only training classification head.\n",
            "Preparing training dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16fecd865b4c4d8aa382c126ba03e730"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing evaluation dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26d88e4c28ba4e6dadd776b5da21cfbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-797312931.py:171: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting transfer learning training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [400/400 09:06, Epoch 100/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.697970</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.695795</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.682300</td>\n",
              "      <td>0.692769</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.682300</td>\n",
              "      <td>0.689941</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.665100</td>\n",
              "      <td>0.688895</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.665100</td>\n",
              "      <td>0.685833</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.665100</td>\n",
              "      <td>0.681208</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.661900</td>\n",
              "      <td>0.677769</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.661900</td>\n",
              "      <td>0.672919</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.616900</td>\n",
              "      <td>0.670441</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.616900</td>\n",
              "      <td>0.668020</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.616900</td>\n",
              "      <td>0.662156</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.601400</td>\n",
              "      <td>0.660122</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.601400</td>\n",
              "      <td>0.659283</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.592200</td>\n",
              "      <td>0.656610</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.592200</td>\n",
              "      <td>0.651226</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.592200</td>\n",
              "      <td>0.646309</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.575600</td>\n",
              "      <td>0.640703</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.575600</td>\n",
              "      <td>0.630578</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.183673</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.582100</td>\n",
              "      <td>0.619513</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.582100</td>\n",
              "      <td>0.609688</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.582100</td>\n",
              "      <td>0.599581</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.537200</td>\n",
              "      <td>0.591262</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.537200</td>\n",
              "      <td>0.583622</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.514700</td>\n",
              "      <td>0.578870</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.514700</td>\n",
              "      <td>0.572695</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.514700</td>\n",
              "      <td>0.567455</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.475500</td>\n",
              "      <td>0.563464</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.475500</td>\n",
              "      <td>0.557268</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.456500</td>\n",
              "      <td>0.551353</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.456500</td>\n",
              "      <td>0.544942</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.456500</td>\n",
              "      <td>0.539031</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.470000</td>\n",
              "      <td>0.532420</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.470000</td>\n",
              "      <td>0.525866</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.451000</td>\n",
              "      <td>0.520583</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.451000</td>\n",
              "      <td>0.516704</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.451000</td>\n",
              "      <td>0.511356</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.425800</td>\n",
              "      <td>0.507605</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.425800</td>\n",
              "      <td>0.502540</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.392700</td>\n",
              "      <td>0.498916</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.392700</td>\n",
              "      <td>0.494534</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.392700</td>\n",
              "      <td>0.490156</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.393200</td>\n",
              "      <td>0.484262</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.393200</td>\n",
              "      <td>0.478369</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.363100</td>\n",
              "      <td>0.472979</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.363100</td>\n",
              "      <td>0.467874</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.363100</td>\n",
              "      <td>0.463539</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.417600</td>\n",
              "      <td>0.459108</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.417600</td>\n",
              "      <td>0.456302</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.314300</td>\n",
              "      <td>0.453511</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.314300</td>\n",
              "      <td>0.450167</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.314300</td>\n",
              "      <td>0.446164</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.347000</td>\n",
              "      <td>0.441663</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.347000</td>\n",
              "      <td>0.439118</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.346000</td>\n",
              "      <td>0.436990</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.346000</td>\n",
              "      <td>0.434738</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.346000</td>\n",
              "      <td>0.432220</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.307700</td>\n",
              "      <td>0.427956</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.307700</td>\n",
              "      <td>0.423267</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.332700</td>\n",
              "      <td>0.419273</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.332700</td>\n",
              "      <td>0.415065</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.332700</td>\n",
              "      <td>0.410585</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.318800</td>\n",
              "      <td>0.405749</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.318800</td>\n",
              "      <td>0.401339</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.304200</td>\n",
              "      <td>0.397033</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.304200</td>\n",
              "      <td>0.393049</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.304200</td>\n",
              "      <td>0.389792</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.321800</td>\n",
              "      <td>0.387083</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.321800</td>\n",
              "      <td>0.384622</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.289400</td>\n",
              "      <td>0.381992</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.289400</td>\n",
              "      <td>0.379714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.289400</td>\n",
              "      <td>0.377377</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.266500</td>\n",
              "      <td>0.374967</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.266500</td>\n",
              "      <td>0.372916</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.287500</td>\n",
              "      <td>0.370784</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.287500</td>\n",
              "      <td>0.368780</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.287500</td>\n",
              "      <td>0.366802</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.263700</td>\n",
              "      <td>0.364751</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.263700</td>\n",
              "      <td>0.363181</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.283500</td>\n",
              "      <td>0.361972</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.283500</td>\n",
              "      <td>0.360789</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.283500</td>\n",
              "      <td>0.359614</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.358514</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.357697</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.251000</td>\n",
              "      <td>0.356635</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.251000</td>\n",
              "      <td>0.355679</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.251000</td>\n",
              "      <td>0.354589</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.260700</td>\n",
              "      <td>0.353554</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.260700</td>\n",
              "      <td>0.352629</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.243200</td>\n",
              "      <td>0.352069</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.243200</td>\n",
              "      <td>0.351524</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.243200</td>\n",
              "      <td>0.350995</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.249000</td>\n",
              "      <td>0.350556</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.249000</td>\n",
              "      <td>0.350095</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.277000</td>\n",
              "      <td>0.349723</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.277000</td>\n",
              "      <td>0.349425</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.277000</td>\n",
              "      <td>0.349222</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.289900</td>\n",
              "      <td>0.349024</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.289900</td>\n",
              "      <td>0.348890</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.254600</td>\n",
              "      <td>0.348843</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transfer learning completed!\n",
            "\n",
            "=== MAKING PREDICTIONS ===\n",
            "Predictions with full fine-tuning: [{'text': 'This product is amazing!', 'predicted_class': 1, 'confidence': 0.6731581687927246}, {'text': 'I hate this so much.', 'predicted_class': 0, 'confidence': 0.5747971534729004}, {'text': 'Pretty decent overall.', 'predicted_class': 1, 'confidence': 0.5548656582832336}]\n",
            "Text: 'This product is amazing!'\n",
            "Prediction: Positive (Confidence: 0.673)\n",
            "------------------------------\n",
            "Text: 'I hate this so much.'\n",
            "Prediction: Negative (Confidence: 0.575)\n",
            "------------------------------\n",
            "Text: 'Pretty decent overall.'\n",
            "Prediction: Positive (Confidence: 0.555)\n",
            "------------------------------\n",
            "\n",
            "=== TESTING SAVED MODEL ===\n",
            "Predictions on new examples: [{'text': 'This is absolutely wonderful!', 'predicted_class': 1, 'confidence': 0.6599050164222717}, {'text': \"I'm really disappointed with this.\", 'predicted_class': 0, 'confidence': 0.551493227481842}, {'text': 'The weather looks great today.', 'predicted_class': 1, 'confidence': 0.6215211153030396}, {'text': 'This is the worst experience ever.', 'predicted_class': 1, 'confidence': 0.5056089758872986}, {'text': 'I love how this works perfectly.', 'predicted_class': 1, 'confidence': 0.551056981086731}]\n",
            "Text: 'This is absolutely wonderful!'\n",
            "Predicted: Positive (Confidence: 0.660)\n",
            "--------------------------------------------------\n",
            "Text: 'I'm really disappointed with this.'\n",
            "Predicted: Negative (Confidence: 0.551)\n",
            "--------------------------------------------------\n",
            "Text: 'The weather looks great today.'\n",
            "Predicted: Positive (Confidence: 0.622)\n",
            "--------------------------------------------------\n",
            "Text: 'This is the worst experience ever.'\n",
            "Predicted: Positive (Confidence: 0.506)\n",
            "--------------------------------------------------\n",
            "Text: 'I love how this works perfectly.'\n",
            "Predicted: Positive (Confidence: 0.551)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}