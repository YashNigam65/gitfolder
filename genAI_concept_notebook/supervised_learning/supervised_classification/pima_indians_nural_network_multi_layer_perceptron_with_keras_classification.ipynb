{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashNigam65/gitfolder/blob/master/notebook/Other/pima_indians_nural_network_multi_layer_perceptron_one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates how to build, train, and evaluate a simple Multilayer Perceptron (MLP) for binary classification using Keras. Specifically, it uses the Pima Indians Diabetes Dataset to predict whether a patient has diabetes based on several health indicators. The process involves:\n",
        "\n",
        "**Introduction to Keras Concepts**: Explaining fundamental Keras components like Layers, Sequential models, and Dense layers.\n",
        "\n",
        "**Data Loading and Preparation**: Loading the dataset and splitting it into input features (X) and target variable (Y).\n",
        "\n",
        "**Model Definition**: Creating a Sequential Keras model with two hidden Dense layers and an output Dense layer.\n",
        "\n",
        "**Model Compilation and Training**: Configuring the model with a loss function, optimizer, and metrics, then training it on the dataset.\n",
        "\n",
        "**Model Evaluation**: Assessing the trained model's accuracy.\n",
        "\n",
        "**Prediction**: Using the trained model to make predictions on new, unseen data samples."
      ],
      "metadata": {
        "id": "Fzviu1TJYmmy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx1tkn0cJIik"
      },
      "source": [
        "**Keras**: Think of Keras as a user-friendly toolkit for building and training neural networks. It sits on top of more complex deep learning frameworks (like TensorFlow) and makes it much easier to design, build, and experiment with neural networks without getting bogged down in the complicated details.\n",
        "\n",
        "\n",
        "**What is it?** Keras is a high-level API (Application Programming Interface) that allows you to quickly create and prototype neural networks. It's designed for ease of use, modularity, and extensibility.\n",
        "\n",
        "**Layer**: In a neural network, a layer is like a step in processing the data. Data goes into one layer, the layer performs some calculations on it, and then the output of that layer becomes the input for the next layer. Think of it like a series of filters or transformations applied to the data.\n",
        "\n",
        "**Sequential**: A Sequential model in Keras is the simplest type of model. It's a linear stack of layers, where you just add layers one after another. Data flows straight through from the first layer to the last layer without any branches or complex connections. It's like building a chain of processing steps.\n",
        "\n",
        "**Dense Layer**: A Dense layer is a type of layer where every neuron in the layer is connected to every neuron in the previous layer. It's also known as a fully connected layer. This is a very common type of layer used in many neural network architectures. It essentially learns a weighted sum of the inputs from the previous layer and applies an activation function to the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dF835PtJIis"
      },
      "source": [
        "Keras (for Neural Networks - MLP in this case):\n",
        "\n",
        "**What it's good for**: Neural networks, especially deep learning models built with frameworks like Keras, are powerful for complex tasks where the relationships between the input features and the output are not simple or linear. They can automatically learn intricate patterns and hierarchies in data. This is particularly useful for things like image recognition, natural language processing, and in this case, potentially capturing non-linear relationships in the diabetes dataset.\n",
        "\n",
        "**How it works**: Neural networks consist of interconnected layers of \"neurons\" that process data in a hierarchical way. They learn by adjusting the \"weights\" of these connections during training to minimize errors.\n",
        "\n",
        "**When to use it**: When you have a large amount of data and suspect there are complex, non-linear relationships that simpler models might miss.\n",
        "KNN (K-Nearest Neighbors):\n",
        "\n",
        "**What it's good for**: KNN is a simple, non-parametric algorithm used for both classification and regression. It works by finding the 'k' nearest data points in the training set to a new data point and making a prediction based on the majority class (for classification) or the average value (for regression) of those neighbors.\n",
        "\n",
        "**How it works**: It's based on the principle that similar data points are likely to have similar outcomes.\n",
        "\n",
        "**When to use it**: KNN is easy to understand and implement. It can be effective for smaller datasets and when the decision boundary is not linear. However, it can be computationally expensive with large datasets.\n",
        "\n",
        "**Linear Regression:**\n",
        "\n",
        "What it's good for: Linear Regression is a supervised learning algorithm used for predicting a continuous output variable based on a linear relationship with the input features.\n",
        "\n",
        "How it works: It finds the best-fitting straight line (or hyperplane in higher dimensions) that minimizes the difference between the predicted and actual output values.\n",
        "\n",
        "When to use it: When you believe there is a linear relationship between your input features and the output variable. It's simple, interpretable, and fast to train.\n",
        "\n",
        "**Logistic Regression:**\n",
        "\n",
        "**What it's good for**: Logistic Regression is a supervised learning algorithm used for binary classification tasks (predicting one of two outcomes). It's similar to linear regression but uses a logistic function to output a probability between 0 and 1.\n",
        "How it works: It models the probability of a data point belonging to a particular class based on a linear combination of the input features.\n",
        "When to use it: When you need to predict a binary outcome and assume a linear relationship between the features and the log-odds of the outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84ab860d"
      },
      "source": [
        "This code cell imports the necessary libraries for building the neural network:\n",
        "*   `Sequential` and `Dense` from `keras.models` and `keras.layers` respectively, which are fundamental components for defining the neural network architecture.\n",
        "*   `numpy` for numerical operations, particularly for handling the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_l3wP3uJIit"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7Mszl2EYHgRA"
      },
      "outputs": [],
      "source": [
        "# Create your first MLP in Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01c770a9"
      },
      "source": [
        "\n",
        "This code cell performs the following steps:\n",
        "*   `numpy.random.seed(7)`: Sets the random seed for reproducibility, ensuring that the model initialization is consistent each time the code is run.\n",
        "*   `dataset = numpy.loadtxt(...)`: Loads the Pima Indians Diabetes dataset from a CSV file. The dataset contains various medical predictors and a binary outcome (diabetes or no diabetes).\n",
        "*   `X = dataset[:,0:8]`: Splits the dataset into input features (`X`), taking the first 8 columns.\n",
        "*   `Y = dataset[:,8]`: Splits the dataset into the output variable (`Y`), which is the 9th column (the target variable indicating diabetes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pK35jltuHi-5"
      },
      "outputs": [],
      "source": [
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"https://raw.githubusercontent.com/YashNigam65/gitfolder/refs/heads/master/dataset/pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bd350b6"
      },
      "source": [
        "This code cell defines the neural network architecture:\n",
        "*   `model = Sequential()`: Initializes a Sequential model, which is a linear stack of layers.\n",
        "*   `model.add(Dense(12, input_dim=8, activation='relu'))`: Adds the first hidden Dense layer with 12 neurons, 8 input dimensions, and a ReLU activation function.\n",
        "*   `model.add(Dense(8, activation='relu'))`: Adds a second hidden Dense layer with 8 neurons and a ReLU activation function.\n",
        "*   `model.add(Dense(1, activation='sigmoid'))`: Adds the output Dense layer with 1 neuron (for binary classification) and a sigmoid activation function, which outputs a probability between 0 and 1.\n",
        "*   `model.summary()`: Prints a summary of the model architecture, including the number of layers, output shapes, and the total number of trainable parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_PJnEjcJIiw"
      },
      "source": [
        "There are some general guidelines, like choosing a number of neurons between the input and output layer size, or perhaps a number related to the input dimension (like half or twice the input features). In this case, the input dimension is 8, and 12 is a value in that general range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "hECj6ciEHm44",
        "outputId": "c9d9eb07-ce1f-49f4-bbb7-e2066fc0c0a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m108\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m221\u001b[0m (884.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221</span> (884.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m221\u001b[0m (884.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221</span> (884.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ReLU** **(Rectified Linear Unit) Function**:\n",
        "\n",
        "What it is: A very common activation function in neural networks. It returns 0 if it receives any negative input, but for any positive value, it returns that value back.\n",
        "\n",
        "Formula: f(x) = max(0, x)\n",
        "\n",
        "Where it's used: Primarily in the hidden layers of neural networks. It helps introduce non-linearity into the model, allowing it to learn complex patterns.\n",
        "\n",
        "Why it's popular: It's computationally efficient (simple calculation) and helps mitigate the vanishing gradient problem, which can occur with other activation functions like sigmoid in deep networks.\n",
        "\n",
        "**Sigmoid** **Function**:\n",
        "\n",
        "What it is: An S-shaped activation function that maps any real-valued number into a value between 0 and 1.\n",
        "\n",
        "Formula: f(x) = 1 / (1 + e^(-x))\n",
        "\n",
        "Where it's used: Most commonly in the output layer of binary classification models (like the one in this notebook). The output, being a probability between 0 and 1, can directly represent the likelihood of a positive class.\n",
        "\n",
        "Why it's used for binary classification: Its output naturally lends itself to probability interpretation, where values close to 1 indicate a high probability of the positive class and values close to 0 indicate a high probability of the negative class."
      ],
      "metadata": {
        "id": "CEcb7hJ3eBqJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "457bfbf2"
      },
      "source": [
        "\n",
        "This cell handles the training and evaluation of the defined Keras model:\n",
        "*   `model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])`: Compiles the model, specifying:\n",
        "    *   `loss='binary_crossentropy'`: The loss function for binary classification.\n",
        "    *   `optimizer='adam'`: The Adam optimizer, a popular choice for neural networks.\n",
        "    *   `metrics=['accuracy']`: The metric to monitor during training and evaluation.\n",
        "*   `model.fit(X, Y, epochs=150, batch_size=10)`: Trains the model using the input data `X` and target `Y` for 150 epochs with a batch size of 10.\n",
        "*   `scores = model.evaluate(X, Y)`: Evaluates the trained model on the same training data to get the final loss and accuracy.\n",
        "*   `print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))`: Prints the final accuracy achieved by the model, which is approximately 76.30% in this run."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**loss='binary_crossentropy'**: This specifies the loss function (also known as the objective function) that the model will try to minimize during training. For binary classification problems (where the output is either 0 or 1, like predicting diabetes or not), binary_crossentropy is the standard and most appropriate choice. It measures how well the model's predicted probabilities match the true labels. A lower loss value means a better-performing model."
      ],
      "metadata": {
        "id": "nLesnHvVgZqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**optimizer='adam'**: This defines the optimizer, which is the algorithm used to update the weights of your neural network during training. The optimizer's job is to adjust the model's internal parameters (weights) in a way that reduces the loss function. 'Adam' (Adaptive Moment Estimation) is a very popular and often highly effective optimizer because it combines the best properties of other optimization algorithms, adapting the learning rate for each weight individually. This typically leads to faster convergence and better performance."
      ],
      "metadata": {
        "id": "-Dao73Nsgbfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**epochs=150**: An epoch represents one complete pass through the entire training dataset. In each epoch, the model sees every training example once, updates its weights, and calculates the loss and metrics. Setting epochs=150 means the model will iterate over the entire X and Y dataset 150 times."
      ],
      "metadata": {
        "id": "MXxv798-gn9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**batch_size=10**: The batch size determines the number of samples that will be propagated through the network at once before the model's weights are updated. Instead of updating weights after every single sample (which can be noisy and slow), or after seeing all samples (which can be memory-intensive for large datasets), training is usually done in mini-batches. With batch_size=10, the training data is divided into smaller chunks of 10 samples, and the model updates its weights after processing each batch. This provides a good balance between training stability and computational efficiency. For example, if you have 768 samples, an epoch would consist of 768 / 10 = 77 (rounded up) batches."
      ],
      "metadata": {
        "id": "gQDdUkNXhSY5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEh4McsuHpgR",
        "outputId": "e98eb0e3-39e0-4477-c852-ce2a1c839097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6384 - loss: 12.7461\n",
            "Epoch 2/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5753 - loss: 3.0101\n",
            "Epoch 3/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6007 - loss: 1.3240\n",
            "Epoch 4/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6244 - loss: 1.2019\n",
            "Epoch 5/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6195 - loss: 1.0687\n",
            "Epoch 6/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6501 - loss: 1.0419\n",
            "Epoch 7/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6556 - loss: 0.8762\n",
            "Epoch 8/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6935 - loss: 0.7907\n",
            "Epoch 9/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7113 - loss: 0.7795\n",
            "Epoch 10/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6662 - loss: 0.8803\n",
            "Epoch 11/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6660 - loss: 0.8013\n",
            "Epoch 12/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6072 - loss: 0.7994\n",
            "Epoch 13/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6338 - loss: 0.7992\n",
            "Epoch 14/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6517 - loss: 0.7411\n",
            "Epoch 15/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6523 - loss: 0.7534\n",
            "Epoch 16/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6713 - loss: 0.6734\n",
            "Epoch 17/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6573 - loss: 0.6961\n",
            "Epoch 18/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7038 - loss: 0.6703\n",
            "Epoch 19/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7055 - loss: 0.6559\n",
            "Epoch 20/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6681 - loss: 0.6584\n",
            "Epoch 21/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6958 - loss: 0.6414\n",
            "Epoch 22/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6994 - loss: 0.6431\n",
            "Epoch 23/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6787 - loss: 0.6959\n",
            "Epoch 24/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6887 - loss: 0.6182\n",
            "Epoch 25/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7270 - loss: 0.5924\n",
            "Epoch 26/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.5507\n",
            "Epoch 27/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7084 - loss: 0.6039\n",
            "Epoch 28/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6743 - loss: 0.6085\n",
            "Epoch 29/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7005 - loss: 0.6037\n",
            "Epoch 30/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6996 - loss: 0.5884\n",
            "Epoch 31/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.5869\n",
            "Epoch 32/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7173 - loss: 0.6071\n",
            "Epoch 33/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7161 - loss: 0.5875\n",
            "Epoch 34/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6778 - loss: 0.6029\n",
            "Epoch 35/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6840 - loss: 0.6057\n",
            "Epoch 36/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7466 - loss: 0.5354\n",
            "Epoch 37/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6858 - loss: 0.5984\n",
            "Epoch 38/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6901 - loss: 0.5998\n",
            "Epoch 39/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.5720\n",
            "Epoch 40/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6934 - loss: 0.6071\n",
            "Epoch 41/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6677 - loss: 0.5994\n",
            "Epoch 42/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.5536\n",
            "Epoch 43/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7255 - loss: 0.5583\n",
            "Epoch 44/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7168 - loss: 0.5585\n",
            "Epoch 45/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7095 - loss: 0.5765\n",
            "Epoch 46/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.5521\n",
            "Epoch 47/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.5762\n",
            "Epoch 48/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 0.5546\n",
            "Epoch 49/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7169 - loss: 0.5292\n",
            "Epoch 50/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7462 - loss: 0.5198\n",
            "Epoch 51/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.5598\n",
            "Epoch 52/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 0.5515\n",
            "Epoch 53/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7193 - loss: 0.5599\n",
            "Epoch 54/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7232 - loss: 0.5312\n",
            "Epoch 55/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7467 - loss: 0.5275\n",
            "Epoch 56/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6960 - loss: 0.6065\n",
            "Epoch 57/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6817 - loss: 0.5862\n",
            "Epoch 58/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7632 - loss: 0.5298\n",
            "Epoch 59/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: 0.5402\n",
            "Epoch 60/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: 0.5508\n",
            "Epoch 61/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.5137\n",
            "Epoch 62/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.5523\n",
            "Epoch 63/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.5305\n",
            "Epoch 64/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.5205\n",
            "Epoch 65/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7181 - loss: 0.5393\n",
            "Epoch 66/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7464 - loss: 0.5329\n",
            "Epoch 67/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7132 - loss: 0.5688\n",
            "Epoch 68/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7569 - loss: 0.5081\n",
            "Epoch 69/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.5601\n",
            "Epoch 70/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7541 - loss: 0.5156\n",
            "Epoch 71/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7843 - loss: 0.4905\n",
            "Epoch 72/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5258\n",
            "Epoch 73/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7358 - loss: 0.5333\n",
            "Epoch 74/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7033 - loss: 0.5454\n",
            "Epoch 75/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.5470\n",
            "Epoch 76/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7405 - loss: 0.5326\n",
            "Epoch 77/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7356 - loss: 0.5237\n",
            "Epoch 78/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7770 - loss: 0.4877\n",
            "Epoch 79/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7629 - loss: 0.5035\n",
            "Epoch 80/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7499 - loss: 0.5239\n",
            "Epoch 81/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7328 - loss: 0.5474\n",
            "Epoch 82/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7167 - loss: 0.5613\n",
            "Epoch 83/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7345 - loss: 0.5436\n",
            "Epoch 84/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7494 - loss: 0.5012\n",
            "Epoch 85/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 0.5429\n",
            "Epoch 86/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7267 - loss: 0.5422\n",
            "Epoch 87/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7337 - loss: 0.5187\n",
            "Epoch 88/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7262 - loss: 0.5368\n",
            "Epoch 89/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7704 - loss: 0.4943\n",
            "Epoch 90/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7579 - loss: 0.4903\n",
            "Epoch 91/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7611 - loss: 0.5388\n",
            "Epoch 92/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7767 - loss: 0.4914\n",
            "Epoch 93/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7703 - loss: 0.4821\n",
            "Epoch 94/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.5177\n",
            "Epoch 95/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7158 - loss: 0.5283\n",
            "Epoch 96/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7593 - loss: 0.4951\n",
            "Epoch 97/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7269 - loss: 0.5615\n",
            "Epoch 98/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7645 - loss: 0.5045\n",
            "Epoch 99/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7641 - loss: 0.5188\n",
            "Epoch 100/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7597 - loss: 0.5222\n",
            "Epoch 101/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7543 - loss: 0.5263\n",
            "Epoch 102/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7822 - loss: 0.4721\n",
            "Epoch 103/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7278 - loss: 0.5183\n",
            "Epoch 104/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7682 - loss: 0.4956\n",
            "Epoch 105/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7542 - loss: 0.5115\n",
            "Epoch 106/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7482 - loss: 0.5440\n",
            "Epoch 107/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7609 - loss: 0.5036\n",
            "Epoch 108/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7089 - loss: 0.5423\n",
            "Epoch 109/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7702 - loss: 0.4801\n",
            "Epoch 110/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7593 - loss: 0.5148\n",
            "Epoch 111/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7656 - loss: 0.4902\n",
            "Epoch 112/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7449 - loss: 0.5074\n",
            "Epoch 113/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7459 - loss: 0.5261\n",
            "Epoch 114/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7697 - loss: 0.5001\n",
            "Epoch 115/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7734 - loss: 0.4885\n",
            "Epoch 116/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7536 - loss: 0.4943\n",
            "Epoch 117/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.5142\n",
            "Epoch 118/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7733 - loss: 0.4881\n",
            "Epoch 119/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7674 - loss: 0.5067\n",
            "Epoch 120/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7304 - loss: 0.5436\n",
            "Epoch 121/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7291 - loss: 0.5078\n",
            "Epoch 122/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7539 - loss: 0.5200\n",
            "Epoch 123/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7751 - loss: 0.4772\n",
            "Epoch 124/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7544 - loss: 0.5131\n",
            "Epoch 125/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7541 - loss: 0.4939\n",
            "Epoch 126/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7587 - loss: 0.4985\n",
            "Epoch 127/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7490 - loss: 0.5113\n",
            "Epoch 128/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7525 - loss: 0.5091\n",
            "Epoch 129/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7679 - loss: 0.4866\n",
            "Epoch 130/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7594 - loss: 0.4924\n",
            "Epoch 131/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7825 - loss: 0.4845\n",
            "Epoch 132/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7474 - loss: 0.5055\n",
            "Epoch 133/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7609 - loss: 0.4913\n",
            "Epoch 134/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7340 - loss: 0.5053\n",
            "Epoch 135/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.5021\n",
            "Epoch 136/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7469 - loss: 0.5042\n",
            "Epoch 137/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7582 - loss: 0.4716\n",
            "Epoch 138/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7712 - loss: 0.4718\n",
            "Epoch 139/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7743 - loss: 0.5509\n",
            "Epoch 140/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7588 - loss: 0.5025\n",
            "Epoch 141/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7591 - loss: 0.5051\n",
            "Epoch 142/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7694 - loss: 0.4839\n",
            "Epoch 143/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7816 - loss: 0.4510\n",
            "Epoch 144/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7503 - loss: 0.4908\n",
            "Epoch 145/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7576 - loss: 0.4685\n",
            "Epoch 146/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7802 - loss: 0.4627\n",
            "Epoch 147/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7547 - loss: 0.4906\n",
            "Epoch 148/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7557 - loss: 0.4872\n",
            "Epoch 149/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7716 - loss: 0.4856\n",
            "Epoch 150/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7714 - loss: 0.4818\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.5100  \n",
            "\n",
            "compile_metrics: 76.17%\n"
          ]
        }
      ],
      "source": [
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ne94Z7xi0heX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Predict diabetes for new samples (3 new patients)\n",
        "samples = np.array([[6, 148, 72, 35, 0, 33.6, 0.627, 50],   # Sample 1\n",
        "                    [1, 85, 66, 29, 0, 26.6, 0.351, 31],    # Sample 2\n",
        "                    [8, 183, 64, 0, 0, 23.3, 0.672, 32]])   # Sample 3\n",
        "\n",
        "# Standardize the new data using the same scaler\n",
        "#samples_scaled = scaler.transform(samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ee0144e"
      },
      "source": [
        "This code cell uses the trained model to predict outcomes for the new samples:\n",
        "*   `predictions = model.predict(samples)`: Uses the `model` to predict the probability of diabetes for each of the three `samples`. The output will be probabilities between 0 and 1.\n",
        "*   `predicted_classes = (predictions > 0.5).astype(int)`: Converts these probabilities into binary class labels (0 or 1). If the probability is greater than 0.5, it's classified as 1 (diabetes); otherwise, it's 0 (no diabetes).\n",
        "*   `print(predicted_classes.flatten())`: Prints the final predicted classes for the samples in a flattened array. Based on the output, the predictions are `[1 0 1]`, meaning the first and third samples are predicted to have diabetes, and the second sample is predicted not to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKzIpAs1042W",
        "outputId": "69d5635c-c948-4a72-9a2d-8571bb6231b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
            "Predictions for the samples (0 = No Diabetes, 1 = Diabetes):\n",
            "[1 0 1]\n"
          ]
        }
      ],
      "source": [
        "# Predict diabetes (returns probabilities)\n",
        "predictions = model.predict(samples)\n",
        "\n",
        "# Convert probabilities to class labels (0 or 1)\n",
        "predicted_classes = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Output predictions\n",
        "print(\"Predictions for the samples (0 = No Diabetes, 1 = Diabetes):\")\n",
        "print(predicted_classes.flatten())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}