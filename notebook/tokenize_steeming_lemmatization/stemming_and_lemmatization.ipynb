{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashNigam65/gitfolder/blob/master/notebook/concept_example/stemming_and_lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook explain the concept of stemming and lemmatization.\n",
        "\n",
        "Stemming and lemmatization are both techniques used in natural language processing (NLP) to reduce words to their base or root form, but they do so in slightly different ways.\n",
        "\n"
      ],
      "metadata": {
        "id": "kkCJ--HTASbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming: This is a more crude process that chops off the ends of words to get to a common \"stem.\" The stem might not always be a grammatically correct word. For example, the stem of \"programming\" and \"programmer\" might be \"programm,\" which isn't a real English word. It's faster but can be less accurate.\n",
        "\n",
        "Example from the notebook:\n",
        "programming becomes program\n",
        "\n",
        "programmer becomes programm\n",
        "\n",
        "Intelligence becomes intellig"
      ],
      "metadata": {
        "id": "c7fZ0-zZAsmS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization (as shown in cell V3U6nqCMmk0s): This is a more sophisticated process that considers the word's meaning and aims to return the base or dictionary form of a word, known as a \"lemma.\" The lemma is always a valid word. It's generally slower but more accurate.\n",
        "\n",
        "Example from the notebook:\n",
        "rocks becomes rock\n",
        "\n",
        "corpora becomes corpus\n",
        "\n",
        "better (as an adjective) becomes good\n",
        "\n",
        "programming becomes programming (it's already a base form in this context)\n",
        "\n",
        "programmer becomes programmer (also a base form)"
      ],
      "metadata": {
        "id": "XqAdJy9GAtnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwFc9WKRmAIl",
        "outputId": "53e7b54c-7888-4258-e22e-a9a8d3d8e311"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "GHH5b3u6mSjT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell downloads the punkt tokenizer from nltk. The punkt tokenizer is used for splitting text into a list of sentences and words, which is a common prerequisite for many NLP tasks."
      ],
      "metadata": {
        "id": "gRt1fdcC-fAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsdEqStImFdU",
        "outputId": "4be9f2e5-428a-473b-9ade-673035d9ea66"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell downloads the wordnet corpus from nltk. WordNet is a lexical database of semantic relations between words, often used for lemmatization."
      ],
      "metadata": {
        "id": "qAK9tS32-rga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVjTj4IRnlcz",
        "outputId": "19b67f85-cf6d-4c18-aeaa-5f40a0e9c513"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell demonstrates stemming using the PorterStemmer from nltk. It initializes a stemmer and then applies it to a list of words, showing how different forms of a word (e.g., \"program\", \"programs\", \"programming\") are reduced to their base or root form (e.g., \"program\", \"programm\")."
      ],
      "metadata": {
        "id": "Gj2qvgQp_HHa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPUqO2I9l-ZM",
        "outputId": "28d7e0c1-6703-4c14-dd38-d57d2248b28a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "program  :  program\n",
            "programs  :  program\n",
            "programmer  :  programm\n",
            "programming  :  program\n",
            "programmers  :  programm\n",
            "Intelligence  :  intellig\n",
            "better  :  better\n"
          ]
        }
      ],
      "source": [
        "# import these modules\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "# choose some words to be stemmed\n",
        "words = [\"program\", \"programs\", \"programmer\", \"programming\", \"programmers\", \"Intelligence\", \"better\"]\n",
        "\n",
        "for w in words:\n",
        "\tprint(w, \" : \", ps.stem(w))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell demonstrates lemmatization using the WordNetLemmatizer from nltk. It initializes a lemmatizer and applies it to various words. Unlike stemming, lemmatization considers the word's meaning and aims to return the base or dictionary form of a word (the 'lemma'), which is often a valid word itself (e.g., \"rocks\" becomes \"rock\", \"better\" with pos=\"a\" (adjective) becomes \"good\").\n",
        "\n"
      ],
      "metadata": {
        "id": "g4RyPPmm_rtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import these modules\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
        "print(\"Intelligence :\", lemmatizer.lemmatize(\"Intelligence\"))\n",
        "\n",
        "\n",
        "# a denotes adjective in \"pos\"\n",
        "print(\"better :\", lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
        "\n",
        "words = [\"program\", \"programs\", \"programmer\", \"programming\", \"programmers\", \"better\"]\n",
        "\n",
        "for w in words:\n",
        "\tprint(w, \" : \", lemmatizer.lemmatize(w))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3U6nqCMmk0s",
        "outputId": "f8e26098-d5bf-41d3-aa1e-4f113187b247"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rocks : rock\n",
            "corpora : corpus\n",
            "Intelligence : Intelligence\n",
            "better : good\n",
            "program  :  program\n",
            "programs  :  program\n",
            "programmer  :  programmer\n",
            "programming  :  programming\n",
            "programmers  :  programmer\n",
            "better  :  better\n"
          ]
        }
      ]
    }
  ]
}