{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashNigam65/gitfolder/blob/master/notebook/Other/tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we see that how tokenisation works."
      ],
      "metadata": {
        "id": "-qnKEA12oKjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93-wg1My_VtV",
        "outputId": "d84b24bb-cffc-4d6c-d774-1d64f5ad22e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk.download('punkt'): NLTK often requires specific data packages (corpora, models, grammars) to perform its tasks. The 'punkt' package contains pre-trained models for sentence tokenization. These models are language-specific and help NLTK accurately identify sentence boundaries within a text."
      ],
      "metadata": {
        "id": "LIQgD1JTofba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk.download('wordnet'): The 'wordnet' package downloads the WordNet lexical database. WordNet is a large, publicly available lexical database of English nouns, verbs, adjectives, and adverbs that are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. It is used for tasks like lemmatization, finding synonyms, and understanding word relationships."
      ],
      "metadata": {
        "id": "r9TXmMXIon1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3O2sHyd_YjM",
        "outputId": "956b82e9-aa3a-406c-a21e-3174c2979bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "ZAptHPhb_YZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9164cdb-6c1c-4ead-ee7a-94e8dd73bd25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0EKDD3BQov4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "word_tokenize: This is a function that takes a string of text and splits it into a list of individual words and punctuation marks.\n",
        "\n",
        "sent_tokenize: This is a function that takes a string of text and splits it into a list of individual sentences."
      ],
      "metadata": {
        "id": "sFqPdEOQo9lK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcouyPns_T0m",
        "outputId": "af8c9e31-503d-4f26-a2c4-4e01fc929f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['In', 'a', 'bizarre', 'incident', 'that', 'has', 'captivated', 'as', 'well', 'as', 'terrified', 'the', 'internet', ',', 'a', 'small', ',', 'AI-powered', 'robot', 'from', 'Hangzhou', 'successfully', 'kidnapped', '12', 'larger', 'robots', 'from', 'a', 'Shanghai', 'robotics', 'company', \"'s\", 'showroom', '.', 'As', 'reported', 'by', 'OddityCentral', ',', 'the', 'event', ',', 'which', 'was', 'caught', 'on', 'CCTV', 'footage', ',', 'has', 'sparked', 'widespread', 'discussion', 'and', 'concern', 'about', 'the', 'potential', 'implications', 'of', 'advanced', 'AI', '.']\n",
            "[\"In a bizarre incident that has captivated as well as terrified the internet, a small, AI-powered robot from Hangzhou successfully kidnapped 12 larger robots from a Shanghai robotics company's showroom.\", 'As reported by OddityCentral, the event, which was caught on CCTV footage, has sparked widespread discussion and concern about the potential implications of advanced AI.']\n"
          ]
        }
      ],
      "source": [
        "# Tokenization using NLTK\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "sent = \"In a bizarre incident that has captivated as well as terrified the internet, a small, AI-powered robot from Hangzhou successfully kidnapped \\\n",
        "12 larger robots from a Shanghai robotics company's showroom. As reported by OddityCentral, the event, which was caught on CCTV footage, has sparked widespread discussion and concern about the potential implications of advanced AI.\"\n",
        "print(word_tokenize(sent))\n",
        "print(sent_tokenize(sent))\n"
      ]
    }
  ]
}