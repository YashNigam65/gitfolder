{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashNigam65/gitfolder/blob/master/notebook/Other/forward_propagate_2_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook serves as an educational tool to explain the foundational steps of how a neural network processes information to generate an output based on an input, without delving into the learning (training) aspect."
      ],
      "metadata": {
        "id": "fuLZwg7r0qMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By working through this notebook, we are achieving a clear and detailed understanding of the forward propagation mechanism in a simplified neural network. Specifically, we are:\n",
        "\n",
        "**Understanding fundamental neural network components**: We've examined the role of the exp function in activation, the activate function in calculating neuron input signals, and the transfer (sigmoid) function in squashing outputs and introducing non-linearity.\n",
        "\n",
        "**Tracing data flow**: The forward_propagate function demonstrates how input data moves sequentially through layers of a neural network, with the output of one layer becoming the input for the next.\n",
        "\n",
        "**Illustrating a complete pass**: The test case shows a practical application of these functions to perform a single forward pass with a given input and network structure."
      ],
      "metadata": {
        "id": "ILsVVt3Z0yLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The exp function from Python's math module was explained as crucial for calculating the exponential component of the sigmoid (logistic) activation function within the transfer function, which is fundamental for neural network operations."
      ],
      "metadata": {
        "id": "LmzfLWAU1fJA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LSGckp6mL-vQ"
      },
      "outputs": [],
      "source": [
        "# Example of forward propagating input\n",
        "from math import exp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The activate function's role in calculating a neuron's raw input signal strength was clarified. It computes the weighted sum of inputs plus the neuron's bias, represented by the last weight."
      ],
      "metadata": {
        "id": "QTD7Iv-V1o13"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R6pNddtaMHEH"
      },
      "outputs": [],
      "source": [
        "# Calculate neuron activation for an input\n",
        "def activate(weights, inputs):\n",
        "\t#print(inputs)\n",
        "\tactivation = weights[-1]\n",
        "\tfor i in range(len(weights)-1):\n",
        "\t\tactivation += weights[i] * inputs[i]\n",
        "\t\t#print(activation)\n",
        "\treturn activation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "transfer function (Sigmoid) functionality: The transfer function was detailed as implementing the sigmoid activation, which squashes an activation value to an output between 0 and 1. This is vital for tasks like classification, providing probabilistic interpretations, and introducing non-linearity to the network."
      ],
      "metadata": {
        "id": "EqjU_zE71yoY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2YVyXbgBMRRt"
      },
      "outputs": [],
      "source": [
        "# Transfer neuron activation\n",
        "def transfer(activation):\n",
        "    p= 1.0 / (1.0 + exp(-activation))\n",
        "    #print(p)\n",
        "    return 1.0 / (1.0 + exp(-activation))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The forward_propagate function was explained as the core mechanism for processing data through the entire neural network. It iteratively applies the activate and transfer functions to each neuron, layer by layer, with the outputs of one layer becoming the inputs for the next."
      ],
      "metadata": {
        "id": "zxfWg8Zt2Lbh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wOMKW-RFMPe_"
      },
      "outputs": [],
      "source": [
        "# Forward propagate input to a network output\n",
        "def forward_propagate(network, row):\n",
        "    inputs = row\n",
        "    for layer in network:\n",
        "\n",
        "        new_inputs = []\n",
        "        for neuron in layer:\n",
        "            #print(neuron)\n",
        "            activation = activate(neuron['weights'], inputs)\n",
        "            neuron['output'] = transfer(activation)\n",
        "            new_inputs.append(neuron['output'])\n",
        "        inputs = new_inputs\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The explanation for the test case provided a clear breakdown of a simple neural network's structure (two layers, each with one neuron), the input data ([1, 0, None]), and how forward_propagate is used to simulate a forward pass, with its output being the network's prediction."
      ],
      "metadata": {
        "id": "Eg1-o-T62g1p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8E5DtQnMUuU",
        "outputId": "3575f2fa-a5ab-4bfb-a99a-e1100fb9a56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6629970129852887]\n"
          ]
        }
      ],
      "source": [
        "# test forward propagation\n",
        "network = [[{'weights': [0.13436424411240122, 0.34564598723719715, 0.763774618976614]}],\n",
        "\t\t[{'weights': [0.2550690257394217, 0.49543508709194095]}]]#, {'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
        "row = [1, 0, None]\n",
        "output = forward_propagate(network, row)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dc377d3"
      },
      "source": [
        "### Explanation of the Test Case\n",
        "\n",
        "This test case demonstrates the `forward_propagate` function with a simple neural network.\n",
        "\n",
        "**Network Structure:**\n",
        "The `network` variable defines a small neural network. It's a list of layers, where each layer is a list of neurons. Each neuron is a dictionary containing its `weights`.\n",
        "- The current `network` has two layers.\n",
        "  - The first layer has one neuron with 3 weights: `[0.13436424411240122, 0.34564598723719715, 0.763774618976614]`.\n",
        "  - The second layer also has one neuron with 2 weights: `[0.2550690257394217, 0.49543508709194095]`.\n",
        "\n",
        "**Input Row:**\n",
        "The `row` variable `[1, 0, None]` represents the input to the neural network. The `None` value suggests a placeholder or that the input size might vary, but in the context of the provided `activate` function, it's expected to align with the number of input weights for the first layer's neurons.\n",
        "\n",
        "**Forward Propagation and Output:**\n",
        "The `forward_propagate(network, row)` function is called to process the `row` input through the defined `network`. It calculates the activations and transfers them through each neuron and layer. The final output of the network, which is the output of the last layer's neurons, is then stored in the `output` variable and printed. This shows the result of a single forward pass through the network with the given input."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "forward_propagate_2_1_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}